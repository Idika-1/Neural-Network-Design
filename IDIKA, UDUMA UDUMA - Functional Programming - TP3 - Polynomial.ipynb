{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae62a04d-8ce8-49f8-b258-5b35fd8f5745",
   "metadata": {},
   "source": [
    "__<h3>Author: IDIKA, UDUMA UDUMA</h3>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02954f-e854-4094-93d2-3cbe5f71e86f",
   "metadata": {},
   "source": [
    "__<h3>Major: Data Management and Artificial Intelligence</h3>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574793ae-b90f-42e9-9941-02c8774ba0a3",
   "metadata": {},
   "source": [
    "__<h3>Topic: Building a Neural Network from Scratch using JAX</h3>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded2800-a868-452c-b5d6-eb7af0353276",
   "metadata": {},
   "source": [
    "__<h3>Objective:</h3>__\n",
    "\n",
    "**Development of a Two-Layer Classification Neural Network from Scratch using JAX.**\n",
    "\n",
    "I achieved this via the following steps:\n",
    "\n",
    "Step 1: Defining the Neural Network Architecture  \n",
    "Step 2: Initializing Weights and Biases <br>\n",
    "Step 3: Implementing the Forward Pass <br>\n",
    "Step 4: Defining the Loss Function <br>\n",
    "Step 5: Implementing the Backpropagation Algorithm <br>\n",
    "Step 6: Updating Model Parameters (Weights and Biases) using Gradient Descent <br>\n",
    "Step 7: Training Loop Implementation <br>\n",
    "Step 8: Evaluating Model Performance <br>\n",
    "Step 9: Evaluating Model Accuracy on Test Set <br>\n",
    "\n",
    "In addition, I developed a Polynomial Basis function as a function approximation model for features transformation \n",
    "before feeding the features through a neural network architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c618dae7-f2e3-4416-af5e-cd8bb3755aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "import jax.random as random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4e139-9b52-4a57-970c-15d5b9f432b1",
   "metadata": {},
   "source": [
    "**<h3>Part A: Development of a Polynomial Basis Function for Features Transformation</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb4474f-dfcb-4f10-a36e-3f0aeb8de7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Understanding and Defining the Iris Dataset\n",
    "\n",
    "#The Iris dataset contains measurements of iris flowers from three different species, namely:\n",
    "# - Setosa (label 0)\n",
    "# - Versicolor (label 1)\n",
    "# - Virginica (label 2)\n",
    "\n",
    "#The target variable in the dataset represents the species of the iris flower based on the three target classes above.\n",
    "\n",
    "#The dataset includes four features (attributes) for each flower, which are:\n",
    "# - Sepal Length: Length of the sepal in centimeters.\n",
    "# - Sepal Width: Width of the sepal in centimeters.\n",
    "# - Petal Length: Length of the petal in centimeters.\n",
    "# - Petal Width: Width of the petal in centimeters.\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "x_iris = iris.data       #Features\n",
    "y_iris = iris.target\n",
    "\n",
    "#Splitting the data into train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_iris, y_iris, test_size = 0.3, random_state=42)\n",
    "\n",
    "degree = 2     #Degree of the polynomial\n",
    "\n",
    "#Step 2: Defining the Polynomial features\n",
    "def poly_features(x, degree):\n",
    "    return jnp.column_stack([x**i for i in range(0, degree+1)])\n",
    "\n",
    "x_poly_train = poly_features(x_train, degree)\n",
    "x_poly_test = poly_features(x_test, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac0092-a90a-457f-b1ee-6d0c463f86cc",
   "metadata": {},
   "source": [
    "**<h3>Part B: Development of a Neural Network Model</h3>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a38b7-078f-4d8c-9a49-781ad855421b",
   "metadata": {},
   "source": [
    "**Note: This Neural Network Implementation is for a 2-layer neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e518867-51dd-4b06-ae8d-df1f7948f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "W1: (12, 12)\n",
      "b1: (12,)\n",
      "W2: (12, 3)\n",
      "b2: (3,)\n",
      "\n",
      "Initial Model Parameters:\n",
      "W1: [[-2.5239918e-01 -2.1174815e-01 -2.2750594e-01  4.2111066e-01\n",
      "  -2.8472772e-01 -1.5529143e-02 -1.6852786e-01  4.3425614e-01\n",
      "  -1.8992077e-01  3.1830138e-01  1.5107836e-01  4.8315726e-02]\n",
      " [ 4.2937317e-01 -4.7053549e-01 -6.1278880e-01 -3.0824658e-01\n",
      "  -4.7150216e-01  1.5280814e-03 -8.9916617e-01  5.1620957e-02\n",
      "   4.3158033e-01  8.1605017e-01 -4.8400378e-03  7.8165710e-02]\n",
      " [-2.7019122e-01  3.4461638e-01  8.5073209e-01 -3.2515216e-01\n",
      "  -1.0735965e-02  3.1049478e-01  2.3683484e-01  2.3175696e-01\n",
      "   1.8891878e-01  5.3888345e-01  4.2159390e-01  3.8556099e-01]\n",
      " [-3.2152638e-01 -1.9946833e-01  5.6027436e-01 -8.4315455e-03\n",
      "   8.8983225e-03 -2.1055153e-01  2.8850397e-02  4.5395754e-02\n",
      "   7.4483804e-02  2.1892242e-01 -2.0953804e-01  8.6590327e-02]\n",
      " [ 4.4984636e-01 -1.7921016e-01  2.7026129e-01  5.3254926e-01\n",
      "   3.0364001e-02  3.0988522e-04  1.7420000e-01  4.2272523e-01\n",
      "  -3.8459611e-01 -9.3017256e-01 -6.0662287e-01  1.0184039e-01]\n",
      " [-3.1671694e-01 -6.7355233e-01  3.3281326e-01  1.0163792e-01\n",
      "   6.7745022e-02  5.3780377e-01 -1.4244176e-01  2.2783948e-01\n",
      "  -4.7268203e-01  5.2069890e-01  5.3832829e-01  1.9870172e-01]\n",
      " [-2.5063112e-01 -3.2665333e-01 -8.1488021e-02 -3.3496210e-01\n",
      "  -2.6484200e-01 -1.9876043e-01  1.3678810e-01  3.7342587e-01\n",
      "   6.8089014e-01  6.3595271e-01  8.7363780e-02 -5.5514053e-02]\n",
      " [ 3.2648340e-01 -8.1021285e-01 -2.2243367e-01 -1.2328732e+00\n",
      "   2.4255641e-01  7.6409569e-03  1.5223967e-01  5.2866149e-01\n",
      "  -1.6914189e-01 -3.1246635e-01 -7.3197234e-01  2.9188776e-01]\n",
      " [-6.3756841e-01  5.0554130e-02  5.3702939e-01  3.3341384e-01\n",
      "   2.5265318e-01 -4.4324079e-01 -2.0692369e-01  1.7061147e-01\n",
      "  -4.5936897e-01 -2.7029338e-01  3.4168839e-01  3.0894890e-01]\n",
      " [-4.9589905e-01  4.1800120e-01  1.7178844e-01  8.3088689e-02\n",
      "   6.8887007e-01 -5.1150084e-02 -4.9809083e-02  2.5198102e-01\n",
      "  -1.0917566e+00 -5.0990599e-01 -2.7086505e-01  7.4212092e-01]\n",
      " [-3.8255519e-01 -7.7040397e-02 -1.6954288e-01 -8.8556580e-02\n",
      "  -1.5461352e-01  1.3397508e+00  3.2117462e-01  3.9862778e-02\n",
      "   5.0760669e-01 -8.7169394e-02  2.0494981e-01  2.7474186e-01]\n",
      " [-4.6607032e-02  1.8700355e-01 -5.6221730e-01 -6.0273808e-01\n",
      "   1.6350764e-01 -1.2775701e-01 -5.1039129e-01  6.6740978e-01\n",
      "  -3.6341786e-01 -6.5693073e-02  2.6542717e-01 -2.7227870e-01]]\n",
      "\n",
      "b1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "W2: [[ 0.01042802 -0.39642     0.09075482]\n",
      " [-0.07360623 -0.22545052  0.466773  ]\n",
      " [-0.0824177  -0.1164467   0.2429716 ]\n",
      " [-0.33782867  0.20966798  0.11162771]\n",
      " [ 0.6912968  -0.04561529  0.12099247]\n",
      " [ 0.85014564  0.88787776  0.06115826]\n",
      " [ 0.16531692  0.2629348  -0.36347243]\n",
      " [-0.5034494  -0.13650653 -0.10549334]\n",
      " [ 0.02790709 -0.32427222  0.8462877 ]\n",
      " [ 0.15675974  0.4063919   0.38864383]\n",
      " [ 0.41605178 -0.33963448 -0.05407964]\n",
      " [ 0.10214736 -0.03852909 -0.30235317]]\n",
      "\n",
      "b2: [0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 1:\n",
    "#Define an initialization function for the weights\n",
    "\n",
    "def initialization_fn(key, shape):\n",
    "        return random.normal(key, shape) * jnp.sqrt(2/shape[0])   #He initialization for ReLU activation\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, key, input_dim, hidden_dim, output_dim):\n",
    "        #Define the parameters of the network\n",
    "        key1, key2 = random.split(key, num=2)\n",
    "        \n",
    "        self.W1 = initialization_fn(key1, (input_dim, hidden_dim))\n",
    "        self.b1 = jnp.zeros(hidden_dim,)                                #biases are initialized to zero\n",
    "\n",
    "        self.W2 = initialization_fn(key2, (hidden_dim, output_dim))\n",
    "        self.b2 = jnp.zeros(output_dim,)\n",
    "\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        z1 = jnp.dot(x, self.W1) + self.b1     #pre-activation of the hidden layer\n",
    "        h = jax.nn.relu(z1)                    #applying ReLU activation for the hidden layer\n",
    "\n",
    "        z2 = jnp.dot(h, self.W2) + self.b2     #pre-activation of the output layer\n",
    "        y_pred = jax.nn.softmax(z2)            #applying Softmax to get the probabilities of the predicted target\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "x = x_poly_train\n",
    "y = y_train\n",
    "\n",
    "#Creating an instance of the NeuralNetwork class\n",
    "main_key = random.PRNGKey(42)\n",
    "input_dim = x.shape[1]\n",
    "hidden_dim = 12                              #Numboer of neurons in the hidden layer\n",
    "output_dim = jnp.unique(y_iris).size         #Number of neurons in the output layer corresponds to the number of distinct classes in the target\n",
    "\n",
    "nn = NeuralNetwork(key=main_key, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)  #The _dim here refers to the number of neurons in each layer\n",
    "\n",
    "#Wrapping the parameters in a \"params\" dictionary\n",
    "params = {\n",
    "    \"W1\": nn.W1,\n",
    "    \"b1\": nn.b1,\n",
    "    \"W2\": nn.W2,\n",
    "    \"b2\": nn.b2\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the target to One-Hot Encoding to obtain y_true\n",
    "num_classes = jnp.unique(y_iris).size\n",
    "y_true = jnp.eye(num_classes)[y_train]\n",
    "\n",
    "#Determine initial y_pred from the initial weights and bias initialization\n",
    "y_pred = nn.forward_pass(x)\n",
    "\n",
    "#Printing the shapes of the model's parameters\n",
    "print(\"\\nModel Architecture:\")\n",
    "for k,v in params.items():\n",
    "    print(f\"{k}: {v.shape}\")\n",
    "\n",
    "\n",
    "#Defining the loss function (cross-entropy)\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -jnp.mean(jnp.sum(y_true * jnp.log(y_pred + 1e-8), axis=1))   #Added 1e-8 to avoid log(0) that causes instability\n",
    "\n",
    "#Defining the loss function wrapper to compute the gradient using the loss function\n",
    "def loss_func(params, x, y_true):\n",
    "    W1, b1, W2, b2 = params[\"W1\"], params[\"b1\"], params[\"W2\"], params[\"b2\"]\n",
    "    \n",
    "    z1 = jnp.dot(x, W1) + b1     #pre-activation of the hidden layer\n",
    "    h = jax.nn.relu(z1)          #applying ReLU activation for the hidden layer\n",
    "\n",
    "    z2 = jnp.dot(h, W2) + b2     #pre-activation of the output layer\n",
    "    y_pred = jax.nn.softmax(z2)\n",
    "    \n",
    "    return cross_entropy_loss(y_true, y_pred)\n",
    "\n",
    "#Automatically determining the gradients during backpropagation\n",
    "grads = grad(loss_func)(params, x, y_true)\n",
    "\n",
    "#Printing the initial values of the Model's parameters (params)\n",
    "print(\"\\nInitial Model Parameters:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"{k}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387468fe-0c41-4304-885f-dcd8713a3a67",
   "metadata": {},
   "source": [
    "**<h3>Model Parameters (Weights & Biases) Update using Gradient Descent  </h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fba1920-b68f-4d98-aaa0-3098ddedcc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Parameters:\n",
      "W1: [[-2.5239918e-01 -2.1174815e-01 -2.2750594e-01  4.2111066e-01\n",
      "  -2.8472772e-01 -1.5529143e-02 -1.6852786e-01  4.3425614e-01\n",
      "  -1.8992077e-01  3.1830138e-01  1.5107836e-01  4.8315726e-02]\n",
      " [ 4.2937317e-01 -4.7053549e-01 -6.1278880e-01 -3.0824658e-01\n",
      "  -4.7150216e-01  1.5280814e-03 -8.9916617e-01  5.1620957e-02\n",
      "   4.3158033e-01  8.1605017e-01 -4.8400378e-03  7.8165710e-02]\n",
      " [-2.7019122e-01  3.4461638e-01  8.5073209e-01 -3.2515216e-01\n",
      "  -1.0735965e-02  3.1049478e-01  2.3683484e-01  2.3175696e-01\n",
      "   1.8891878e-01  5.3888345e-01  4.2159390e-01  3.8556099e-01]\n",
      " [-3.2152638e-01 -1.9946833e-01  5.6027436e-01 -8.4315455e-03\n",
      "   8.8983225e-03 -2.1055153e-01  2.8850397e-02  4.5395754e-02\n",
      "   7.4483804e-02  2.1892242e-01 -2.0953804e-01  8.6590327e-02]\n",
      " [ 4.4984636e-01 -1.7921016e-01  2.7026129e-01  5.3254926e-01\n",
      "   3.0364001e-02  3.0988522e-04  1.7420000e-01  4.2272523e-01\n",
      "  -3.8459611e-01 -9.3017256e-01 -6.0662287e-01  1.0184039e-01]\n",
      " [-3.1671694e-01 -6.7355233e-01  3.3281326e-01  1.0163792e-01\n",
      "   6.7745022e-02  5.3780377e-01 -1.4244176e-01  2.2783948e-01\n",
      "  -4.7268203e-01  5.2069890e-01  5.3832829e-01  1.9870172e-01]\n",
      " [-2.5063112e-01 -3.2665333e-01 -8.1488021e-02 -3.3496210e-01\n",
      "  -2.6484200e-01 -1.9876043e-01  1.3678810e-01  3.7342587e-01\n",
      "   6.8089014e-01  6.3595271e-01  8.7363780e-02 -5.5514053e-02]\n",
      " [ 3.2648340e-01 -8.1021285e-01 -2.2243367e-01 -1.2328732e+00\n",
      "   2.4255641e-01  7.6409569e-03  1.5223967e-01  5.2866149e-01\n",
      "  -1.6914189e-01 -3.1246635e-01 -7.3197234e-01  2.9188776e-01]\n",
      " [-6.3756841e-01  5.0554130e-02  5.3702939e-01  3.3341384e-01\n",
      "   2.5265318e-01 -4.4324079e-01 -2.0692369e-01  1.7061147e-01\n",
      "  -4.5936897e-01 -2.7029338e-01  3.4168839e-01  3.0894890e-01]\n",
      " [-4.9589905e-01  4.1800120e-01  1.7178844e-01  8.3088689e-02\n",
      "   6.8887007e-01 -5.1150084e-02 -4.9809083e-02  2.5198102e-01\n",
      "  -1.0917566e+00 -5.0990599e-01 -2.7086505e-01  7.4212092e-01]\n",
      " [-3.8255519e-01 -7.7040397e-02 -1.6954288e-01 -8.8556580e-02\n",
      "  -1.5461352e-01  1.3397508e+00  3.2117462e-01  3.9862778e-02\n",
      "   5.0760669e-01 -8.7169394e-02  2.0494981e-01  2.7474186e-01]\n",
      " [-4.6607032e-02  1.8700355e-01 -5.6221730e-01 -6.0273808e-01\n",
      "   1.6350764e-01 -1.2775701e-01 -5.1039129e-01  6.6740978e-01\n",
      "  -3.6341786e-01 -6.5693073e-02  2.6542717e-01 -2.7227870e-01]]\n",
      "\n",
      "b1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "W2: [[ 0.01042802 -0.39642     0.09075482]\n",
      " [-0.07360623 -0.22545052  0.466773  ]\n",
      " [-0.0824177  -0.1164467   0.2429716 ]\n",
      " [-0.33782867  0.20966798  0.11162771]\n",
      " [ 0.6912968  -0.04561529  0.12099247]\n",
      " [ 0.85014564  0.88787776  0.06115826]\n",
      " [ 0.16531692  0.2629348  -0.36347243]\n",
      " [-0.5034494  -0.13650653 -0.10549334]\n",
      " [ 0.02790709 -0.32427222  0.8462877 ]\n",
      " [ 0.15675974  0.4063919   0.38864383]\n",
      " [ 0.41605178 -0.33963448 -0.05407964]\n",
      " [ 0.10214736 -0.03852909 -0.30235317]]\n",
      "\n",
      "b2: [0. 0. 0.]\n",
      "\n",
      "\n",
      "Updated Model Parameters:\n",
      "W1: [[-2.5239918e-01 -2.1210736e-01 -2.2771890e-01  4.2290533e-01\n",
      "  -2.8715324e-01 -1.5738431e-02 -1.6858459e-01  4.3543118e-01\n",
      "  -1.8992077e-01  3.1830138e-01  1.4855812e-01  4.7937553e-02]\n",
      " [ 4.2937317e-01 -4.7089469e-01 -6.1300176e-01 -3.0645192e-01\n",
      "  -4.7392768e-01  1.3187919e-03 -8.9922291e-01  5.2796017e-02\n",
      "   4.3158033e-01  8.1605017e-01 -7.3602675e-03  7.7787541e-02]\n",
      " [-2.7019122e-01  3.4425718e-01  8.5051912e-01 -3.2335749e-01\n",
      "  -1.3161477e-02  3.1028548e-01  2.3677811e-01  2.3293202e-01\n",
      "   1.8891878e-01  5.3888345e-01  4.1907367e-01  3.8518283e-01]\n",
      " [-3.2152638e-01 -1.9982754e-01  5.6006140e-01 -6.6368757e-03\n",
      "   6.4728111e-03 -2.1076082e-01  2.8793663e-02  4.6570815e-02\n",
      "   7.4483804e-02  2.1892242e-01 -2.1205828e-01  8.6212158e-02]\n",
      " [ 4.4984636e-01 -1.8097802e-01  2.6925722e-01  5.4341245e-01\n",
      "   1.5710261e-02 -9.5693697e-04  1.7389779e-01  4.2991590e-01\n",
      "  -3.8459611e-01 -9.3017256e-01 -6.2175673e-01  9.9318184e-02]\n",
      " [-3.1671694e-01 -6.7474592e-01  3.3210680e-01  1.0635220e-01\n",
      "   6.1359212e-02  5.3724378e-01 -1.4257243e-01  2.3088591e-01\n",
      "  -4.7268203e-01  5.2069890e-01  5.3164560e-01  1.9782861e-01]\n",
      " [-2.5063112e-01 -3.2716992e-01 -8.1634514e-02 -3.2635766e-01\n",
      "  -2.7638522e-01 -1.9987996e-01  1.3652268e-01  3.7929901e-01\n",
      "   6.8089014e-01  6.3595271e-01  7.5652555e-02 -5.8042549e-02]\n",
      " [ 3.2648340e-01 -8.1029475e-01 -2.2239499e-01 -1.2300944e+00\n",
      "   2.3883705e-01  7.2092214e-03  1.5214851e-01  5.3058171e-01\n",
      "  -1.6914189e-01 -3.1246635e-01 -7.3571783e-01  2.9100087e-01]\n",
      " [-6.3756841e-01  4.1814476e-02  5.3232789e-01  3.9933068e-01\n",
      "   1.6387203e-01 -4.5094526e-01 -2.0854986e-01  2.1462472e-01\n",
      "  -4.5936897e-01 -2.7029338e-01  2.5044915e-01  2.9250640e-01]\n",
      " [-4.9589905e-01  4.1400439e-01  1.6941899e-01  9.5497519e-02\n",
      "   6.7201149e-01 -5.2657869e-02 -5.0110333e-02  2.5986016e-01\n",
      "  -1.0917566e+00 -5.0990599e-01 -2.8867200e-01  7.4023986e-01]\n",
      " [-3.8255519e-01 -7.7793770e-02 -1.6878785e-01 -4.9912795e-02\n",
      "  -2.0631719e-01  1.3339134e+00  3.1993020e-01  6.6626787e-02\n",
      "   5.0760669e-01 -8.7169394e-02  1.5295373e-01  2.6223025e-01]\n",
      " [-4.6607032e-02  1.8698172e-01 -5.6199771e-01 -5.9879696e-01\n",
      "   1.5824856e-01 -1.2859918e-01 -5.1053840e-01  6.7017835e-01\n",
      "  -3.6341786e-01 -6.5693073e-02  2.6018488e-01 -2.7367133e-01]]\n",
      "\n",
      "W2: [[ 0.01042802 -0.39642     0.09075482]\n",
      " [-0.07265661 -0.2254555   0.46582836]\n",
      " [-0.14175195 -0.05213509  0.23799424]\n",
      " [-0.36771142  0.24373774  0.10744072]\n",
      " [ 0.6600822  -0.00965006  0.11624185]\n",
      " [ 0.812053    0.91900474  0.06812385]\n",
      " [ 0.16529071  0.26293808 -0.36344948]\n",
      " [-0.55865914 -0.08094624 -0.10584389]\n",
      " [ 0.02790709 -0.32427222  0.8462877 ]\n",
      " [ 0.15675974  0.4063919   0.38864383]\n",
      " [ 0.37283084 -0.29872426 -0.05176893]\n",
      " [ 0.02478539  0.04100705 -0.30452734]]\n",
      "\n",
      "b1: [ 0.0000000e+00 -3.5921013e-04 -2.1296466e-04  1.7946698e-03\n",
      " -2.4255109e-03 -2.0928949e-04 -5.6733570e-05  1.1750592e-03\n",
      "  0.0000000e+00  0.0000000e+00 -2.5202294e-03 -3.7817165e-04]\n",
      "\n",
      "b2: [-0.00322655  0.0035136  -0.00028704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Since JAX is designed for functional programming, \n",
    "#we will return updated parameters instead of modifying parameters in place\n",
    "\n",
    "learning_rate=0.01\n",
    "\n",
    "def update_params(params, gradients, learning_rate):\n",
    "    \"\"\"\n",
    "    Performs a gradient descent update on the neural network parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    - params: Dictionary containing the initial model parameters (W1, b1, W2, b2).\n",
    "    - gradients: Gradient function output from JAX, same structure as params.\n",
    "    - learning_rate: Step size for parameter updates.\n",
    "    \n",
    "    Returns:\n",
    "    - Updated parameters.\n",
    "    \"\"\"\n",
    "    updated_params = jax.tree_util.tree_map(lambda p, g: p - learning_rate * g, params, gradients)\n",
    "    return updated_params\n",
    "\n",
    "#Testing the function using our existing sample data\n",
    "\n",
    "updated_params = update_params(params, grads, learning_rate)\n",
    "\n",
    "#Printing the initial values of the Model's parameters (params)\n",
    "print(\"Initial Model Parameters:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"{k}: {v}\\n\")\n",
    "\n",
    "#Printing the values of the model's updated_parameters\n",
    "print(\"\\nUpdated Model Parameters:\")\n",
    "for k, v in updated_params.items():\n",
    "    print(f\"{k}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6676cf-f6b4-4630-8d68-cb1d14beecd6",
   "metadata": {},
   "source": [
    "**<h3>Training Loop Implementation</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62854a37-5461-4257-8bef-8e631dd9504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 8.5053\n",
      "Epoch 10: Loss = 0.6112\n",
      "Epoch 20: Loss = 0.8464\n",
      "Epoch 30: Loss = 0.4906\n",
      "Epoch 40: Loss = 0.3523\n",
      "Epoch 50: Loss = 0.2777\n",
      "Epoch 60: Loss = 0.2391\n",
      "Epoch 70: Loss = 0.2163\n",
      "Epoch 80: Loss = 0.1994\n",
      "Epoch 90: Loss = 0.1858\n",
      "\n",
      "Final Model Parameters:\n",
      "W1: [[-0.25239918 -0.21442063 -0.23431809  0.42006046 -0.27661458 -0.02530389\n",
      "  -0.16929173  0.4220623  -0.18992077  0.31830138  0.14545351  0.04911644]\n",
      " [ 0.42937317 -0.47320792 -0.61960083 -0.3092968  -0.463389   -0.00824669\n",
      "  -0.8999301   0.03942725  0.43158033  0.8160502  -0.01046493  0.07896645]\n",
      " [-0.27019122  0.34194395  0.84392005 -0.32620236 -0.00262292  0.30072016\n",
      "   0.23607096  0.21956332  0.18891878  0.53888345  0.41596898  0.38636178]\n",
      " [-0.32152638 -0.20214081  0.5534623  -0.0094817   0.01701137 -0.2203263\n",
      "   0.02808653  0.03320204  0.0744838   0.21892242 -0.21516289  0.08739107]\n",
      " [ 0.44984636 -0.19280404  0.23558727  0.5273466   0.04733618 -0.0628985\n",
      "   0.1695396   0.3770004  -0.3845961  -0.93017256 -0.64002985  0.08378334]\n",
      " [-0.31671694 -0.68297863  0.31169856  0.08652329  0.09613694  0.50866604\n",
      "  -0.1444769   0.1924366  -0.47268203  0.5206989   0.5357895   0.19775501]\n",
      " [-0.25063112 -0.3305794  -0.09266411 -0.31907493 -0.30634817 -0.2540724\n",
      "   0.13257784  0.38061613  0.68089014  0.6359527   0.04441765 -0.09888313]\n",
      " [ 0.3264834  -0.81086874 -0.2238746  -1.2290322   0.2215336  -0.01288981\n",
      "   0.15100682  0.5379592  -0.16914189 -0.31246635 -0.7436971   0.27102593]\n",
      " [-0.6375684  -0.01889532  0.35873467  0.27949455  0.19390595 -0.8558235\n",
      "  -0.23577045  0.04605401 -0.45936897 -0.27029338  0.17281395  0.0624582 ]\n",
      " [-0.49589905  0.3844489   0.10478161  0.00236728  0.79004776 -0.13893749\n",
      "  -0.05526334  0.14488721 -1.0917566  -0.509906   -0.23726217  0.7317559 ]\n",
      " [-0.3825552  -0.0828975  -0.18274914 -0.09870169 -0.47303072  1.0266175\n",
      "   0.29770702  0.2251219   0.5076067  -0.08716939  0.11387648 -0.09014282]\n",
      " [-0.04660703  0.18681411 -0.559393   -0.61877406  0.11785834 -0.171191\n",
      "  -0.5124303   0.70216763 -0.36341786 -0.06569307  0.27403134 -0.33115375]]\n",
      "\n",
      "W2: [[ 0.01042802 -0.39642     0.09075482]\n",
      " [-0.06533152 -0.22806585  0.46111372]\n",
      " [ 0.00168346  0.10983143 -0.0674077 ]\n",
      " [-0.23553601  0.28815874 -0.06915562]\n",
      " [ 0.87161773  0.06198331 -0.16692694]\n",
      " [ 0.7462067   0.83576035  0.21721509]\n",
      " [ 0.16519511  0.26250196 -0.36291772]\n",
      " [-0.597105   -0.21297297  0.0646291 ]\n",
      " [ 0.02790709 -0.32427222  0.8462877 ]\n",
      " [ 0.15675974  0.4063919   0.38864383]\n",
      " [ 0.27948126 -0.29838017  0.04123662]\n",
      " [ 0.12664385 -0.06575505 -0.29962385]]\n",
      "\n",
      "b1: [ 0.         -0.00267251 -0.00681212 -0.00105015  0.00811305 -0.00977476\n",
      " -0.00076387 -0.01219369  0.          0.         -0.00562489  0.00080074]\n",
      "\n",
      "b2: [ 0.00710058  0.01892664 -0.02602721]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This entails structuring our training process to iteratively update the parameters over multiple epochs\n",
    "epochs = 100\n",
    "def train_model(params, x_train, y_train, epochs, learning_rate):\n",
    "    \"\"\"\n",
    "    Trains the neural network using gradient descent.\n",
    "\n",
    "    Arguments:\n",
    "    - params: Dictionary of initial model parameters.\n",
    "    - x_train: Input training data.\n",
    "    - y_train: True labels (one-hot encoded).\n",
    "    - epochs: Number of iterations for training.\n",
    "    - learning_rate: Step size for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "    - params: Trained parameters after `epochs` iterations.\n",
    "    - epoch_list: A list that contains some specified epochs\n",
    "    - loss_list: A list that contains the loss for for the specified epochs\n",
    "    \"\"\"\n",
    "    epoch_list = []\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #Compute gradients\n",
    "        grads = grad(loss_func)(params, x_train, y_train)\n",
    "\n",
    "        #Update parameters\n",
    "        params = update_params(params, grads, learning_rate)\n",
    "\n",
    "        #Compute loss after 10 epochs for monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            loss = loss_func(params, x_train, y_train)\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "            loss_value = float(loss)\n",
    "            epoch_list.append(epoch)\n",
    "            loss_list.append(round(loss_value, 4))\n",
    "\n",
    "    return params, epoch_list, loss_list\n",
    "        \n",
    "#Testing the training loop\n",
    "x_train = x.copy()\n",
    "y_train = y_true.copy()\n",
    "\n",
    "final_params, epoch_list, loss_list = train_model(params, x_train, y_train, epochs, learning_rate)\n",
    "\n",
    "#Printing the final model parameters\n",
    "print(f\"\\nFinal Model Parameters:\")\n",
    "for k, v in final_params.items():\n",
    "    print(f\"{k}: {v}\\n\")\n",
    "\n",
    "#Visualizing the loss over the epoch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(loss_list)\n",
    "#print(epoch_list)\n",
    "plt.plot(epoch_list, loss_list)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbc915-f86d-416d-971e-1254c08f58f6",
   "metadata": {},
   "source": [
    "**<h3>Evaluating Model Performance </h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93880c4-452d-4b0e-b5c9-65bffd06bafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 0.1756\n",
      "\n",
      "Predicted Values: [[2.14915406e-02 8.85179520e-01 9.33289751e-02]\n",
      " [6.42684754e-04 4.22234207e-01 5.77123106e-01]\n",
      " [2.54305080e-04 1.80660397e-01 8.19085300e-01]\n",
      " [3.17153297e-02 9.33388114e-01 3.48966196e-02]\n",
      " [1.84592805e-04 6.41963407e-02 9.35619056e-01]\n",
      " [3.20539586e-02 8.34156632e-01 1.33789420e-01]\n",
      " [8.52063113e-06 3.95902321e-02 9.60401297e-01]\n",
      " [1.63524169e-02 6.24745071e-01 3.58902484e-01]\n",
      " [9.88109529e-01 1.18893292e-02 1.23171833e-06]\n",
      " [6.67391441e-06 3.90013829e-02 9.60992038e-01]\n",
      " [1.76032707e-02 9.01509583e-01 8.08871314e-02]\n",
      " [9.81796443e-01 1.82014517e-02 2.04921707e-06]\n",
      " [9.89914417e-01 1.00844083e-02 1.19446656e-06]\n",
      " [9.94339049e-01 5.66033646e-03 5.40295673e-07]\n",
      " [1.04274210e-02 7.38032341e-01 2.51540214e-01]\n",
      " [1.17614400e-03 3.54804069e-01 6.44019783e-01]\n",
      " [9.65977669e-01 3.40065956e-02 1.57988943e-05]\n",
      " [8.97695959e-01 1.02243997e-01 6.00678468e-05]\n",
      " [9.65705216e-01 3.42836492e-02 1.11190302e-05]\n",
      " [1.44197103e-02 7.53429890e-01 2.32150406e-01]\n",
      " [9.79637802e-01 2.03590058e-02 3.13687678e-06]\n",
      " [4.33304794e-02 8.65930736e-01 9.07387882e-02]\n",
      " [2.70545679e-05 9.41276476e-02 9.05845225e-01]\n",
      " [9.62406337e-01 3.75718139e-02 2.17850793e-05]\n",
      " [2.57033762e-02 9.08619225e-01 6.56774119e-02]\n",
      " [2.60574190e-04 5.32188527e-02 9.46520627e-01]\n",
      " [9.99606788e-01 3.93265043e-04 4.09716927e-09]\n",
      " [5.87237999e-03 4.32384968e-01 5.61742663e-01]\n",
      " [3.06380243e-04 8.15892369e-02 9.18104410e-01]\n",
      " [5.04701538e-03 8.91112506e-01 1.03840478e-01]\n",
      " [1.39538972e-02 5.29317319e-01 4.56728756e-01]\n",
      " [1.32849172e-03 9.02071372e-02 9.08464313e-01]\n",
      " [6.77719759e-03 6.72218382e-01 3.21004391e-01]\n",
      " [9.97299969e-01 2.69990298e-03 7.91829891e-08]\n",
      " [4.57102992e-02 8.46189797e-01 1.08099863e-01]\n",
      " [1.71729102e-04 1.33193210e-01 8.66635084e-01]\n",
      " [9.73215759e-01 2.67784782e-02 5.77753053e-06]\n",
      " [9.68187511e-01 3.18053439e-02 7.11079156e-06]\n",
      " [1.69533212e-02 8.46811712e-01 1.36235043e-01]\n",
      " [4.34649922e-03 7.16990829e-01 2.78662652e-01]\n",
      " [9.36451197e-01 6.35178089e-02 3.10707073e-05]\n",
      " [1.15963572e-04 1.91833079e-02 9.80700731e-01]\n",
      " [9.79826033e-01 2.01701913e-02 3.75737113e-06]\n",
      " [9.87634063e-01 1.23632159e-02 2.71960766e-06]\n",
      " [1.44982226e-02 4.96613175e-01 4.88888621e-01]\n",
      " [1.75079390e-01 7.90335178e-01 3.45854498e-02]\n",
      " [1.89478116e-04 9.21398774e-02 9.07670677e-01]\n",
      " [4.38363029e-04 2.16951698e-01 7.82609940e-01]\n",
      " [2.31241895e-04 1.29047334e-01 8.70721340e-01]\n",
      " [1.86268135e-05 9.40427557e-02 9.05938685e-01]\n",
      " [1.37452343e-02 7.43299901e-01 2.42954850e-01]\n",
      " [8.94807637e-01 1.05013818e-01 1.78519753e-04]\n",
      " [9.43566501e-01 5.63717745e-02 6.17767582e-05]\n",
      " [4.00499353e-04 2.08385170e-01 7.91214347e-01]\n",
      " [6.52529052e-05 2.30963424e-01 7.68971324e-01]\n",
      " [9.38794136e-01 6.11543804e-02 5.14496169e-05]\n",
      " [9.88587618e-01 1.14110652e-02 1.25412339e-06]\n",
      " [9.32346940e-01 6.75721020e-02 8.09642297e-05]\n",
      " [5.08144323e-04 4.30814058e-01 5.68677783e-01]\n",
      " [3.22309206e-04 4.13052291e-02 9.58372414e-01]\n",
      " [9.83665526e-01 1.63284913e-02 5.92771403e-06]\n",
      " [2.49368692e-04 1.60080507e-01 8.39670181e-01]\n",
      " [2.58309119e-05 7.68106431e-03 9.92293119e-01]\n",
      " [9.65887487e-01 3.40978429e-02 1.47540659e-05]\n",
      " [5.93751669e-03 7.24541724e-01 2.69520730e-01]\n",
      " [7.93720875e-03 8.47315371e-01 1.44747347e-01]\n",
      " [2.85738823e-03 4.29187566e-01 5.67955077e-01]\n",
      " [2.66282856e-02 9.52770650e-01 2.06011403e-02]\n",
      " [1.14109158e-03 1.16124019e-01 8.82734835e-01]\n",
      " [9.95991051e-01 4.00867360e-03 2.26659651e-07]\n",
      " [1.05984532e-03 3.07430297e-01 6.91509783e-01]\n",
      " [5.80140688e-02 8.36320460e-01 1.05665430e-01]\n",
      " [1.12406618e-03 2.65711635e-01 7.33164310e-01]\n",
      " [7.07176626e-02 9.03493762e-01 2.57885624e-02]\n",
      " [3.81004736e-02 7.03142464e-01 2.58757055e-01]\n",
      " [1.35652209e-02 8.11647236e-01 1.74787492e-01]\n",
      " [5.79210520e-01 4.18837458e-01 1.95205223e-03]\n",
      " [9.98390093e-03 9.24683571e-01 6.53325096e-02]\n",
      " [3.85060138e-03 5.89484811e-01 4.06664580e-01]\n",
      " [9.94321108e-01 5.67868585e-03 2.52836486e-07]\n",
      " [6.35059178e-02 8.37822556e-01 9.86715704e-02]\n",
      " [2.80226086e-05 1.00945972e-01 8.99026036e-01]\n",
      " [2.86642462e-04 1.32193789e-01 8.67519557e-01]\n",
      " [9.94880199e-01 5.11942897e-03 3.83403886e-07]\n",
      " [6.12025447e-02 8.32324207e-01 1.06473245e-01]\n",
      " [1.65622259e-04 3.92353944e-02 9.60599065e-01]\n",
      " [9.39465972e-05 3.94703150e-01 6.05202973e-01]\n",
      " [9.92159128e-01 7.84007739e-03 8.50827291e-07]\n",
      " [1.16723466e-04 4.79413569e-02 9.51941907e-01]\n",
      " [9.19425845e-01 8.05296972e-02 4.45107107e-05]\n",
      " [9.36179608e-03 9.13874030e-01 7.67641738e-02]\n",
      " [3.02090048e-05 1.33050889e-01 8.66918862e-01]\n",
      " [1.53128873e-04 9.75332633e-02 9.02313590e-01]\n",
      " [3.09427697e-02 8.41374516e-01 1.27682745e-01]\n",
      " [1.79888011e-04 1.80128664e-01 8.19691479e-01]\n",
      " [2.28736317e-03 7.87913144e-01 2.09799498e-01]\n",
      " [2.66967174e-02 9.30629432e-01 4.26738188e-02]\n",
      " [4.85203927e-04 7.94295967e-02 9.20085192e-01]\n",
      " [8.42941925e-04 1.87140018e-01 8.12017083e-01]\n",
      " [9.73067760e-01 2.69291978e-02 2.98946861e-06]\n",
      " [4.56787236e-02 9.10058379e-01 4.42628488e-02]\n",
      " [1.32066617e-03 1.01591468e-01 8.97087932e-01]\n",
      " [9.99070227e-01 9.29813599e-04 5.65785774e-09]\n",
      " [2.00569406e-02 8.76297474e-01 1.03645600e-01]\n",
      " [4.15243740e-05 9.11462381e-02 9.08812284e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Compute the final loss of the model\n",
    "final_loss = loss_func(final_params, x_train, y_train)\n",
    "print(f\"Final Loss: {final_loss:.4f}\")\n",
    "\n",
    "#Implementing a predict function to make predictions using the final_params\n",
    "def predict(params, x):\n",
    "    z1 = jnp.dot(x, params[\"W1\"]) + params[\"b1\"]\n",
    "    h = jax.nn.relu(z1)\n",
    "\n",
    "    z2 = jnp.dot(h, params[\"W2\"]) + params[\"b2\"]\n",
    "    y_pred = jax.nn.softmax(z2)\n",
    "    return y_pred\n",
    "\n",
    "#Prediction on training data\n",
    "y_pred = predict(final_params, x_train)\n",
    "print(f\"\\nPredicted Values: {y_pred}\")\n",
    "\n",
    "#Evaluating Model Performance\n",
    "def compute_accuracy(y_pred, y_true):\n",
    "    \"\"\"Compute accuracy by comparing predicted and actual labels\"\"\"\n",
    "    predicted_labels = jnp.argmax(y_pred, axis=1)  #Getting the class with the highest probability\n",
    "    actual_labels = jnp.argmax(y_true, axis=1)     #Getting the actual class labels\n",
    "    accuracy = jnp.mean(predicted_labels == actual_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e2df72e-ddbc-4545-8354-c24683b0c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 98.10%\n"
     ]
    }
   ],
   "source": [
    "#Computing the training accuracy\n",
    "accuracy = compute_accuracy(y_pred, y_train)\n",
    "print(f\"\\nTraining Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1bd1c-8c26-415d-92be-08e11d01d3b5",
   "metadata": {},
   "source": [
    "**<h3>Evaluating Model Accuracy on the Test Set</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b16d2f-ba19-455d-8db6-5f562cf9161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy: 97.78%\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test data\n",
    "y_pred_test = predict(final_params, x_poly_test)\n",
    "\n",
    "y_true_test = jnp.eye(num_classes)[y_test]   #One-hot encoded values of the y_test\n",
    "\n",
    "#Computing the test accuracy\n",
    "accuracy_test = compute_accuracy(y_pred_test, y_true_test)\n",
    "print(f\"\\nTesting Accuracy: {accuracy_test * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed435404-665d-40a1-a032-58ee32193a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
